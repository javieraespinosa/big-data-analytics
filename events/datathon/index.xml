<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Analisis of Web Archives from the Digital Humanities | Big Data Analytics</title><link>https://espinosa-oviedo.com/big-data-analytics/events/datathon/</link><atom:link href="https://espinosa-oviedo.com/big-data-analytics/events/datathon/index.xml" rel="self" type="application/rss+xml"/><description>Analisis of Web Archives from the Digital Humanities</description><generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language><image><url>https://espinosa-oviedo.com/big-data-analytics/media/icon_hua2ec155b4296a9c9791d015323e16eb5_11927_512x512_fill_lanczos_center_3.png</url><title>Analisis of Web Archives from the Digital Humanities</title><link>https://espinosa-oviedo.com/big-data-analytics/events/datathon/</link></image><item><title>The Web &amp; the Digital Humanities</title><link>https://espinosa-oviedo.com/big-data-analytics/events/datathon/description/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://espinosa-oviedo.com/big-data-analytics/events/datathon/description/</guid><description>&lt;h3 id="motivation">Motivation&lt;/h3>
&lt;p>The amount of cultural information that is generated every day on the Web presents new opportunities for historians, political scientists, sociologists, linguists, computer scientists, and other scholars. Much of this information is captured within &lt;strong>web archives&lt;/strong> (&lt;a href="https://en.wikipedia.org/wiki/Web_ARChive" target="_blank" rel="noopener">WARC&lt;/a>) created by organizations such as the &lt;a href="https://archive.org" target="_blank" rel="noopener">Internet Archive&lt;/a>, the &lt;a href="https://www.bnf.fr/fr/archives-de-linternet" target="_blank" rel="noopener">BnF&lt;/a>, and &lt;a href="https://www.bl.uk/collection-guides/uk-web-archive" target="_blank" rel="noopener">The British Library&lt;/a>&lt;sup id="fnref:1">&lt;a href="#fn:1" class="footnote-ref" role="doc-noteref">1&lt;/a>&lt;/sup>. By collaborating with these institutions, scholars from the &lt;a href="https://en.wikipedia.org/wiki/Digital_humanities" target="_blank" rel="noopener">digital humanities&lt;/a> can use web archives to study human production. For instance:&lt;/p>
&lt;ul>
&lt;li>To study Latin American Women’s Rights Movements through Language, Time and Space.&lt;/li>
&lt;li>For comparing the way countries conduct online political campaigns.&lt;/li>
&lt;li>To analyze the public opinion on social media platforms (e.g., #metoo).&lt;/li>
&lt;/ul>
&lt;p>Due to the massive &lt;strong>volume&lt;/strong> and the &lt;strong>variety&lt;/strong> of information available on web archives (e.g., webpages, PDFs, images, videos, audio), manually exploring web archives is a complex and time-consuming task. In this context, data science and Big Data technologies offer an opportunity to extract &lt;strong>value&lt;/strong> from large collections of WARCs files like &lt;a href="http://commoncrawl.org/" target="_blank" rel="noopener">Common Crawl&lt;/a>.&lt;/p>
&lt;h3 id="objective">Objective&lt;/h3>
&lt;p>Through this datathon, participants will :&lt;/p>
&lt;ul>
&lt;li>
&lt;p>Develop awareness about &lt;strong>new analytical requirements&lt;/strong> resulting from the &lt;a href="https://en.wikipedia.org/wiki/Datafication" target="_blank" rel="noopener">datafication&lt;/a> phenomena that call for data science expertise.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Put into practice&lt;/strong> participants&amp;rsquo; &lt;strong>Big Data technical skills&lt;/strong> to analyse and explore web archives produced in the context of the &lt;a href="https://projet-lifranum.univ-lyon3.fr/" target="_blank" rel="noopener">LINFRANUM&lt;/a> (&lt;code>Cartographie de la Littérature Française Numérique&lt;/code>) project.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Develop &lt;a href="https://www.forbes.com/sites/brentdykes/2016/03/31/data-storytelling-the-essential-data-science-skill-everyone-needs/" target="_blank" rel="noopener">storytelling skills&lt;/a> to explain analytical pipelines to technical and non-technical experts.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;p>The datathon will heavily use of &lt;a href="http://spark.apache.org/" target="_blank" rel="noopener">Apache Spark&lt;/a> and the &lt;a href="https://archivesunleashed.org/about-project/" target="_blank" rel="noopener">Archives Unleashed Toolkit&lt;/a>, a project that makes petabytes of historical internet content accessible to scholars and others interested in researching the digital recent past.&lt;/p>
&lt;h3 id="learning-outcomes">Learning Outcomes&lt;/h3>
&lt;p>Regarding Spark you will be able to:&lt;/p>
&lt;ul>
&lt;li>Prepare a Spark environment in an externalised computing environment and schematically explain the underlying functional architecture.&lt;/li>
&lt;li>Transfrom unstructured data collections into tabular representation (i.e. make sure that you can explain the necessity of this transformation and its benefits related to the use of Spark)&lt;/li>
&lt;li>Design and explain a data exploration pipeline using Spark operators.&lt;/li>
&lt;/ul>
&lt;p>Regarding data storytelling, you will be able to:&lt;/p>
&lt;ul>
&lt;li>Import visualization tools into your notebook.&lt;/li>
&lt;li>Produce code to feed visualization functions.&lt;/li>
&lt;li>Provide insight (textual) to describe input data and interpret data processing results.&lt;/li>
&lt;li>Understand the architecture behind your notebook with the storage services, Spark data processing and the visualization tool(s).&lt;/li>
&lt;/ul>
&lt;div class="footnotes" role="doc-endnotes">
&lt;hr>
&lt;ol>
&lt;li id="fn:1">
&lt;p>&lt;a href="https://archivesunleashed.org/cohorts2022-2023/" target="_blank" rel="noopener">https://archivesunleashed.org/cohorts2022-2023/&lt;/a>&amp;#160;&lt;a href="#fnref:1" class="footnote-backref" role="doc-backlink">&amp;#x21a9;&amp;#xfe0e;&lt;/a>&lt;/p>
&lt;/li>
&lt;/ol>
&lt;/div></description></item><item><title>Instructions</title><link>https://espinosa-oviedo.com/big-data-analytics/events/datathon/instructions/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://espinosa-oviedo.com/big-data-analytics/events/datathon/instructions/</guid><description>&lt;p>Given a collection of WARC files (and working in teams), you will have to:&lt;/p>
&lt;ol>
&lt;li>Profile the content of the WARC files using a &lt;strong>quantitative approach&lt;/strong>.&lt;/li>
&lt;li>Explore the WARC files following a &lt;strong>data science approach&lt;/strong> (i.e., hypothesis definition and validation).&lt;/li>
&lt;li>Present your findings to a jury and peers during a &lt;strong>demofest&lt;/strong>.&lt;/li>
&lt;/ol>
&lt;p>The following sections describe each of these phases in detail.&lt;/p>
&lt;h3 id="phase-1-data-profiling">Phase 1: Data Profiling&lt;/h3>
&lt;p>The objective of this phase is to help you get acquainted with the data (i.e., understand data structure, numerical values distribution, identifying outliers and null values).&lt;/p>
&lt;p>&lt;strong>Example&lt;/strong>:&lt;/p>
&lt;ul>
&lt;li>Count all media types contained in a WARC file (e.g., images, webpages, videos).&lt;/li>
&lt;li>Plot the distribution of media types and their storage space usage.&lt;/li>
&lt;/ul>
&lt;p>&lt;mark>The list of &lt;strong>statistics to compute&lt;/strong> is in the &lt;a href="../queries">Queries&lt;/a> section.&lt;/mark>&lt;/p>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: For phase 1, the usage of &lt;strong>Apache Spark is mandatory&lt;/strong>.&lt;/p>
&lt;/blockquote>
&lt;h3 id="phase-2-data-exploration">Phase 2: Data Exploration&lt;/h3>
&lt;p>Once you have a basic understanding of your dataset’s content, you can do a more in deep analysis following the scientific principle:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>Formulate a &lt;code>hypothesis&lt;/code> or &lt;code>research question&lt;/code> according to the insight you obtained in the previous task.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Validate it using analytics techniques (e.g., natural language processing, machine learning, data mining, graph analytics).&lt;/p>
&lt;/li>
&lt;/ol>
&lt;p>&lt;strong>Example&lt;/strong>&lt;/p>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Hypothesis&lt;/strong>: Writers prefer public blog platforms (e.g., Blogger, WordPress) rather than creating/installing their websites from scratch.&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Validation&lt;/strong>: Web pages can contain a &lt;a href="https://www.w3schools.com/tags/tag_meta.asp" target="_blank" rel="noopener">meta tag&lt;/a> describing the technology used for producing the web page. For instance:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-html" data-lang="html">&lt;span class="line">&lt;span class="cl"> &lt;span class="p">&amp;lt;&lt;/span>&lt;span class="nt">meta&lt;/span> &lt;span class="na">name&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;generator&amp;#34;&lt;/span> &lt;span class="na">content&lt;/span>&lt;span class="o">=&lt;/span>&lt;span class="s">&amp;#34;WordPress 3.0.1&amp;#34;&lt;/span> &lt;span class="p">/&amp;gt;&lt;/span>
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>By counting the frequency of occurrences of this metatag in the dataset, it is possible to identify the most popular platforms used in the litterature community.&lt;/p>
&lt;/li>
&lt;/ul>
&lt;blockquote>
&lt;p>&lt;strong>Note&lt;/strong>: For phase 2, the usage of &lt;strong>Apache Spark is optional&lt;/strong>&lt;/p>
&lt;/blockquote>
&lt;h3 id="phase-3-demofest">Phase 3: Demofest&lt;/h3>
&lt;p>The final phase consists of preparing a &lt;strong>presentation&lt;/strong> and a &lt;strong>poster&lt;/strong> to report your findings during the &lt;strong>demofest&lt;/strong>.&lt;/p>
&lt;p>The presentation and poster must answer the following questions:&lt;/p>
&lt;ul>
&lt;li>What data do you work with (which data collection, its volume MB, etc.)?&lt;/li>
&lt;li>How did you divide the work among team members?&lt;/li>
&lt;li>What hypothesis did you propose? Why?&lt;/li>
&lt;li>What type of Spark operations did you apply (Did they work? Did they provide expected results?)&lt;/li>
&lt;li>What is the architecture of the infraestructure that you used? How the components and libraries interact with your Notebook(s)?&lt;/li>
&lt;li>Conclusions (go back to the learning outcomes and discuss which ones could be achieved or not through the exercise)&lt;/li>
&lt;/ul>
&lt;p>The presentation and poster should be complemented with a &amp;ldquo;demo&amp;rdquo; (e.g., using a notebook, a visualization tool or a video) showing your findings and the technical aspects involving your analysis.&lt;/p>
&lt;p>For this phase, you can &lt;mark>&lt;strong>use the &lt;a href="https://archivesunleashed.org/new-york/" target="_blank" rel="noopener">Archives Unleashed New York Datathon&lt;/a> projects as reference&lt;/strong>&lt;/mark>.&lt;/p></description></item><item><title>Evaluation</title><link>https://espinosa-oviedo.com/big-data-analytics/events/datathon/evaluation/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://espinosa-oviedo.com/big-data-analytics/events/datathon/evaluation/</guid><description>&lt;h3 id="to-hand-in">To Hand-in&lt;/h3>
&lt;div class="alert alert-note">
&lt;div>
To hand-in the demofest day!
&lt;/div>
&lt;/div>
&lt;ul>
&lt;li>A table declaring the &lt;strong>level of implication and tasks realized&lt;/strong> per group member.&lt;/li>
&lt;li>&lt;strong>Notebooks&lt;/strong> containing the spark queries and visualizations developed during phase 1 and phase 2.&lt;/li>
&lt;li>&lt;strong>Datasets&lt;/strong> and associated files (e.g., Gephi files, or WARC files in case you run a crawling operation)&lt;/li>
&lt;li>&lt;strong>Instructions&lt;/strong> for running your notebooks.&lt;/li>
&lt;li>&lt;strong>Presentation and demo&lt;/strong> files.&lt;/li>
&lt;/ul>
&lt;h3 id="grading">Grading&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;strong>Analytical operations&lt;/strong> (&lt;code>35%&lt;/code>)&lt;/p>
&lt;ul>
&lt;li>Understanding of the technology in use (e.g., system architecture)&lt;/li>
&lt;li>Limitations of the current solution and ideas on how to proceed when confronted with biggest datasets&lt;/li>
&lt;li>Precision and quality of results&lt;/li>
&lt;li>Originality concerning the hypothesis and results&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Presentation&lt;/strong> (&lt;code>35%&lt;/code>)&lt;/p>
&lt;ul>
&lt;li>Clarity, coherence, pertinence of graphs and demo&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Teamwork&lt;/strong> (&lt;code>15%&lt;/code>)&lt;/p>
&lt;ul>
&lt;li>Organization, distribution of responsibilities, communication&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;strong>Reproducibility&lt;/strong> (&lt;code>15%&lt;/code>)&lt;/p>
&lt;ul>
&lt;li>A jury member should be able to reproduce your results using your notebooks and dataset without modifications!&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Resources</title><link>https://espinosa-oviedo.com/big-data-analytics/events/datathon/resources/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://espinosa-oviedo.com/big-data-analytics/events/datathon/resources/</guid><description>
&lt;details class="toc-inpage d-print-none " open>
&lt;summary class="font-weight-bold">Table of Contents&lt;/summary>
&lt;nav id="TableOfContents">
&lt;ul>
&lt;li>
&lt;ul>
&lt;li>&lt;a href="#dataset">Dataset&lt;/a>&lt;/li>
&lt;li>&lt;a href="#notebooks">Notebooks&lt;/a>&lt;/li>
&lt;li>&lt;a href="#visualization-tools">Visualization Tools&lt;/a>&lt;/li>
&lt;li>&lt;a href="#online-docs">Online docs&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul>
&lt;/nav>
&lt;/details>
&lt;h3 id="dataset">Dataset&lt;/h3>
&lt;div class="alert alert-warning">
&lt;div>
&lt;strong>Do not dowload the files using the web browser!&lt;/strong>&lt;br>
Use the code provided in the notebooks instead.
&lt;/div>
&lt;/div>
&lt;ul>
&lt;li>&lt;a href="https://drive.google.com/drive/folders/1mg1n3ojNwg8J61WWMdlO6M344EE6x1Yc?usp=sharing" target="_blank" rel="noopener">LIFRANUM datasets&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://docs.google.com/spreadsheets/d/1A7NndS96T7c3nH45M2isuxb9c1awbfsw/edit?usp=sharing&amp;amp;ouid=111004351597243537219&amp;amp;rtpof=true&amp;amp;sd=true" target="_blank" rel="noopener">LIFRANUM input URLs&lt;/a>&lt;/li>
&lt;/ul>
&lt;p>The WARC files are organized into 4 categories:&lt;/p>
&lt;div class="highlight">&lt;pre tabindex="0" class="chroma">&lt;code class="language-fallback" data-lang="fallback">&lt;span class="line">&lt;span class="cl"> WARC collection Size
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> ====================================
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Lifranum-method 2.84 Gb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Cartoweb 336 Mb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> autres 721 Mb
&lt;/span>&lt;/span>&lt;span class="line">&lt;span class="cl"> Repo-ecriture-num 158 Mb
&lt;/span>&lt;/span>&lt;/code>&lt;/pre>&lt;/div>&lt;p>Each category name corresponds to the methodology used in the &lt;a href="https://projet-lifranum.univ-lyon3.fr/" target="_blank" rel="noopener">LINFRANUM&lt;/a> project for defining the web crawler input list. For each &lt;code>url&lt;/code> in the list, the web crawler retrieved:&lt;/p>
&lt;ul>
&lt;li>
&lt;p>all ressources &lt;strong>1-level away&lt;/strong> from the URLs used as input (see &lt;a href="https://docs.google.com/spreadsheets/d/1A7NndS96T7c3nH45M2isuxb9c1awbfsw/edit?usp=sharing&amp;amp;ouid=111004351597243537219&amp;amp;rtpof=true&amp;amp;sd=true" target="_blank" rel="noopener">LIFRANUM curated URLs&lt;/a>)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>all ressources (i.e., &lt;strong>recursively&lt;/strong>) &lt;strong>within the same domain&lt;/strong>&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="notebooks">Notebooks&lt;/h3>
&lt;div class="alert alert-note">
&lt;div>
&lt;strong>Docker compatible notebooks&lt;/strong> available at the &lt;strong>&lt;a href="https://github.com/javieraespinosa/big-data-analytics-datathon" target="_blank" rel="noopener">Datathon repository&lt;/a>&lt;/strong>.
&lt;/div>
&lt;/div>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://drive.google.com/file/d/1rKWC1OjhQNVIryelRTrX9uN3_E8yx92e/view?usp=sharing" target="_blank" rel="noopener">Datathon WebArchives Demo&lt;/a> notebook&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://colab.research.google.com/drive/1aL5O2gQBvseLvp61ll_iU48n_HyHkY91?usp=sharing" target="_blank" rel="noopener">Datathon WebArchives Quickstart&lt;/a> notebook&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/javieraespinosa/big-data-analytics-datathon/blob/main/notebooks/03-WebArchives%20Graph%20Analytics.ipynb" target="_blank" rel="noopener">Datathon WebArchives &amp;amp; Graph Analytics&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://colab.research.google.com/drive/1Ss260r20PwfQunYWvuLjZ2Ljcnu9kSlZ?usp=sharing" target="_blank" rel="noopener">Collecting Data from Blogger via the API&lt;/a> notebook&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://github.com/archivesunleashed/notebooks/blob/main/datathon-nyc/parquet_text_analyis_popline.ipynb" target="_blank" rel="noopener">AUT text analysis&lt;/a> notebook&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="visualization-tools">Visualization Tools&lt;/h3>
&lt;ul>
&lt;li>
&lt;p>&lt;a href="https://gephi.org/" target="_blank" rel="noopener">Gephi&lt;/a>: Graph Visualization Platform&lt;/p>
&lt;ul>
&lt;li>see &lt;a href="https://gephi.org/tutorials/gephi-tutorial-quick_start.pdf" target="_blank" rel="noopener">Gephi quick tutorial&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://voyant-tools.org/" target="_blank" rel="noopener">Voyant tools&lt;/a>: analysis environment for digital texts.&lt;/p>
&lt;ul>
&lt;li>see &lt;a href="https://voyant-tools.org/docs/#!/guide/tutorial" target="_blank" rel="noopener">Voyant Tutorial&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://www.rawgraphs.io/" target="_blank" rel="noopener">Rawgraphs&lt;/a>&lt;/p>
&lt;/li>
&lt;li>
&lt;p>&lt;a href="https://plotly.com/python/plotly-express/" target="_blank" rel="noopener">Plotly Express&lt;/a> (python library)&lt;/p>
&lt;/li>
&lt;/ul>
&lt;h3 id="online-docs">Online docs&lt;/h3>
&lt;ul>
&lt;li>&lt;a href="https://sparkbyexamples.com" target="_blank" rel="noopener">Spark by Examples&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://aut.docs.archivesunleashed.org/docs/0.91.0/home" target="_blank" rel="noopener">Archives Unleashed Tools (0.91.0)&lt;/a>: Framework for analyzing web archives with Apache Spark&lt;/li>
&lt;li>&lt;a href="https://spark.apache.org/docs/3.0.0/" target="_blank" rel="noopener">Spark (3.0.0)&lt;/a>
&lt;ul>
&lt;li>&lt;a href="https://spark.apache.org/docs/3.0.0/api/sql/index.html" target="_blank" rel="noopener">Spark SQL Built-in Functions&lt;/a>&lt;/li>
&lt;li>&lt;a href="https://spark.apache.org/docs/3.0.0/api/python/pyspark.sql.html#pyspark.sql.DataFrame" target="_blank" rel="noopener">Spark Dataframe API&lt;/a>&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ul></description></item><item><title>Profiling Queries (phase 1)</title><link>https://espinosa-oviedo.com/big-data-analytics/events/datathon/queries/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://espinosa-oviedo.com/big-data-analytics/events/datathon/queries/</guid><description>&lt;h2 id="schema">Schema&lt;/h2>
&lt;p>To answer the profiling queries, you need to extend the dataframe returned by the AUT &lt;a href="https://aut.docs.archivesunleashed.org/docs/0.91.0/dataframe-schemas#web-pages" target="_blank" rel="noopener">.webpages()&lt;/a> method as shown in the &lt;strong>extended schema&lt;/strong> below.&lt;/p>
&lt;p>Note that:&lt;/p>
&lt;ul>
&lt;li>all new columns are derivated from the &lt;code>url&lt;/code> column.&lt;/li>
&lt;li>the derivation can be done using the &lt;a href="https://github.com/john-kurkowski/tldextract" target="_blank" rel="noopener">tldextract&lt;/a> and &lt;a href="https://docs.python.org/3/library/urllib.parse.html" target="_blank" rel="noopener">urllib.parse&lt;/a> libraries.&lt;/li>
&lt;/ul>
&lt;p>&lt;strong>Extended Schema&lt;/strong>&lt;/p>
&lt;pre>
df.webpages()
|
|-- crawl_date
|-- mime_type_web_server
|-- mime_type_tika
|-- language
|-- content
|-- url: http://forums.news.cnn.com:80/
|-- url_host_name: forums.news.cnn.com
|-- url_domain: cnn
|-- url_subdomain: forums.news
|-- url_tld: com
|-- url_registered_domain: cnn.com
|-- url_domain_reversed: com.cnn.news.forums
|-- url_protocol: http
|-- url_host_port: 80
&lt;/pre>
&lt;p>&lt;code>Optional&lt;/code> (see &lt;a href="https://en.wikipedia.org/wiki/List_of_HTTP_header_fields" target="_blank" rel="noopener">HTTP header fields&lt;/a>)&lt;/p>
&lt;pre>
url_host_ip 192.168.1.10 cf. log.txt file
content_length Content-Length: 348 cf. content’s HTTP header
content_charset Content-Type: text/html; charset=utf-8 cf. content’s HTTP header
&lt;/pre>
&lt;h2 id="queries">Queries&lt;/h2>
&lt;p>The following queries must be computed usning the WARC data collection of your choice.&lt;/p>
&lt;h3 id="domain-names">Domain names&lt;/h3>
&lt;ol>
&lt;li>
&lt;p>Which are the &lt;strong>top registered domains&lt;/strong> (see &lt;a href="https://commoncrawl.github.io/cc-crawl-statistics/plots/domains.html" target="_blank" rel="noopener">example&lt;/a>)?&lt;/p>
&lt;ul>
&lt;li>&lt;code>#&lt;/code> urls per domain&lt;/li>
&lt;li>&lt;code>%&lt;/code> domain urls in collection&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Which are the &lt;strong>Top TLD &amp;amp; gTLDs domains&lt;/strong> (see &lt;a href="https://commoncrawl.github.io/cc-crawl-statistics/plots/tld/latestcrawl.html" target="_blank" rel="noopener">example&lt;/a>)?&lt;/p>
&lt;ul>
&lt;li>see &lt;a href="https://kinsta.com/knowledgebase/what-is-a-tld/" target="_blank" rel="noopener">What Is a TLD?&lt;/a> for more information&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Identify &lt;strong>domains having more than one TLD&lt;/strong> (e.g., &lt;code>amazon/.com/.fr&lt;/code>).&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Identify &lt;strong>subdomains&lt;/strong> for each domain.&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="urls">URLs&lt;/h3>
&lt;ol start="5">
&lt;li>
&lt;p>Compute the &lt;strong>distribution of the URLs components&lt;/strong>. For instance:&lt;/p>
&lt;ul>
&lt;li>&lt;code>http&lt;/code>/&lt;code>https&lt;/code>&lt;/li>
&lt;li>&lt;code>port&lt;/code> number&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Count the &lt;strong>number of words&lt;/strong> used in URLs&lt;/p>
&lt;ul>
&lt;li>e.g., split URLs at &lt;code>.&lt;/code> (dot) and &lt;code>-&lt;/code> (hyphen)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;/ol>
&lt;h3 id="web-pages-content">Web pages content&lt;/h3>
&lt;ol start="7">
&lt;li>
&lt;p>Compute the &lt;strong>list of languages&lt;/strong> used in webpages?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Compute the &lt;strong>distribution&lt;/strong> of: &lt;/p>
&lt;ul>
&lt;li>&lt;code>MIME types&lt;/code> (see &lt;a href="https://commoncrawl.github.io/cc-crawl-statistics/plots/mimetypes" target="_blank" rel="noopener">example&lt;/a>)&lt;/li>
&lt;li>&lt;code>languages&lt;/code> (see &lt;a href="https://commoncrawl.github.io/cc-crawl-statistics/plots/languages" target="_blank" rel="noopener">example&lt;/a>)&lt;/li>
&lt;li>&lt;code>charsets&lt;/code> (see &lt;a href="https://commoncrawl.github.io/cc-crawl-statistics/plots/charsets" target="_blank" rel="noopener">example&lt;/a>) (&lt;strong>optional&lt;/strong>)&lt;/li>
&lt;/ul>
&lt;/li>
&lt;li>
&lt;p>Identify &lt;strong>page titles&lt;/strong> (&lt;strong>optional&lt;/strong>)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="collection--hosts">Collection &amp;amp; Hosts&lt;/h3>
&lt;ol start="10">
&lt;li>
&lt;p>&lt;strong>How many pages, per language&lt;/strong>, were collected per host?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>What is the &lt;strong>total number of bytes&lt;/strong> that was collected by the crawler for each host?&lt;/p>
&lt;/li>
&lt;li>
&lt;p>What is the &lt;strong>ratio between the webpages and Web ressources&lt;/strong> that were collected per host? (&lt;strong>optional&lt;/strong>)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>For each host, &lt;strong>list the servers IPs&lt;/strong> to which the crawler interacted to. Then, determine whether custom domains point to any of these hosts (&lt;strong>optional&lt;/strong>)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="images">Images&lt;/h3>
&lt;ol start="14">
&lt;li>
&lt;p>Identify the &lt;strong>largest/smallest image&lt;/strong> in the dataset (&lt;code>width&lt;/code> x &lt;code>height&lt;/code>)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Identify the images appearing in the data collection under different names (i.e., &lt;strong>images having the same MD5 hash&lt;/strong>)&lt;/p>
&lt;/li>
&lt;li>
&lt;p>Find images shared between more than 2 domains (&lt;a href="https://aut.docs.archivesunleashed.org/docs/0.91.0/image-analysis#pythondf" target="_blank" rel="noopener">example&lt;/a>)&lt;/p>
&lt;/li>
&lt;/ol>
&lt;h3 id="web-graph">Web graph&lt;/h3>
&lt;ol start="15">
&lt;li>Identify &lt;strong>domains with strong/weak connectivity&lt;/strong>&lt;/li>
&lt;/ol>
&lt;h3 id="multimedia">Multimedia&lt;/h3>
&lt;ol start="16">
&lt;li>Compute the statistics of the multimedia files within the data collection (&lt;strong>optional&lt;/strong>)&lt;/li>
&lt;/ol></description></item><item><title>Teams</title><link>https://espinosa-oviedo.com/big-data-analytics/events/datathon/teams/</link><pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate><guid>https://espinosa-oviedo.com/big-data-analytics/events/datathon/teams/</guid><description>&lt;h3 id="teams-eti">Teams ETI&lt;/h3>
&lt;blockquote>
&lt;p>See the &lt;a href="https://docs.google.com/spreadsheets/d/10c-1467qzDoIvuEIFi1BzO4JRuImfWmL/edit?usp=sharing&amp;amp;ouid=111004351597243537219&amp;amp;rtpof=true&amp;amp;sd=true" target="_blank" rel="noopener">GoogleDoc version&lt;/a> in case of visualization problems.&lt;/p>
&lt;/blockquote>
&lt;div class="responsive-wrap">
&lt;iframe src="https://docs.google.com/spreadsheets/d/10c-1467qzDoIvuEIFi1BzO4JRuImfWmL/edit?usp=sharing&amp;amp;ouid=111004351597243537219&amp;amp;rtpof=true&amp;amp;sd=true" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true">&lt;/iframe>
&lt;/div>
&lt;hr>
&lt;h3 id="teams-irc">Teams IRC&lt;/h3>
&lt;blockquote>
&lt;p>See the &lt;a href="https://docs.google.com/spreadsheets/d/1soIknJCaVUu1IlP64suv0xqRBtWE1dA0/edit?usp=sharing&amp;amp;ouid=111004351597243537219&amp;amp;rtpof=true&amp;amp;sd=true" target="_blank" rel="noopener">GoogleDoc version&lt;/a> in case of visualization problems.&lt;/p>
&lt;/blockquote>
&lt;div class="responsive-wrap">
&lt;iframe src="https://docs.google.com/spreadsheets/d/1soIknJCaVUu1IlP64suv0xqRBtWE1dA0/edit?usp=sharing&amp;amp;ouid=111004351597243537219&amp;amp;rtpof=true&amp;amp;sd=true" frameborder="0" width="960" height="569" allowfullscreen="true" mozallowfullscreen="true" webkitallowfullscreen="true">&lt;/iframe>
&lt;/div></description></item></channel></rss>